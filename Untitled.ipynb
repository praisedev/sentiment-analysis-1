{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "from IPython.core.interactiveshell import InteractiveShell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "# Set dataframe options to keep long data in columns from being truncated with ellipsis (...)\n",
    "pd.set_option('max_colwidth', None)\n",
    "\n",
    "# Set dataframe options to force display max columns\n",
    "pd.set_option('display.max_columns', 90)\n",
    "pd.set_option('display.max_rows', 90)\n",
    "\n",
    "InteractiveShell.ast_node_interactivity = \"all\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def df_info(df):\n",
    "    '''\n",
    "    A helper function - similar in functionality with `df.info()` but includes combined features: df.columns, df.dtypes, \n",
    "    df.isnull(), df.info(), df.nunique()\n",
    "    '''\n",
    "    print('\\nShape : {}'.format(df.shape))\n",
    "    print('Number of duplicates : {}\\n'.format(df.duplicated().sum()))\n",
    "    print('{:^35} {:^12} {:^12} {:^8} {:>10}\\n'.format('COLUMNS', 'DATA TYPE', 'HAS NULL', 'COUNTS', '# UNIQUE'))\n",
    "    for i, v in enumerate(df.columns):\n",
    "        col = df[v]\n",
    "        dtype = type(col.iloc[0]).__name__\n",
    "        \n",
    "        if dtype=='dict':\n",
    "            keys = set([item for val in col.values if val is not None for item in list(val.keys())])\n",
    "            col_nunique = len(keys)\n",
    "        else:\n",
    "            col_nunique = col.nunique()\n",
    "        \n",
    "        print(' {:>2}.  {:<30} {:<12} {:^10} {:>8} {:>10}'.format(i+1, v, dtype, \\\n",
    "                                                                  str(col.isnull().any()), col.count(), \\\n",
    "                                                                  col_nunique))    # col.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Shape : (1699302, 2)\n",
      "Number of duplicates : 0\n",
      "\n",
      "              COLUMNS                DATA TYPE     HAS NULL    COUNTS    # UNIQUE\n",
      "\n",
      "  1.  text                           str            False     1699302    1699302\n",
      "  2.  sentiment                      int64          False     1699302          3\n"
     ]
    }
   ],
   "source": [
    "# persist the under-sampled data\n",
    "reviews_dataset = pd.read_csv('../yelp_dataset/reviews_dataset_under-sampled.csv')\n",
    "df_info(reviews_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1597603</th>\n",
       "      <td>Lindo's is a great neighborhood breakfast and lunch spot. Their Special Greek omelet is a wonder to behold. Stuffed with gyro meat, spinach, feta, and tomatoes, it's gigantic but somehow doesn't make me feel like death after eating it. I also love, love, love that you can get grits as your side instead of home fries. Very nice service, and quick on the coffee refills. I'm eager to try their weekend breakfast buffet, as well as their lunch items.</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>825216</th>\n",
       "      <td>Okay so where do I start, this place is a long time family owned business in Lakewood. It's very well known for their pizza. I've had on numerous occasions and I have mixed feelings about it. Angelo's is definitely an overrated by quite a bit. Some of their pizzas can be quite greasy and their sauce may need some sugar to tone down the acidity of it. However I think they do really well with their different kinds of unique pizzas that you can't find anywhere else, from BBQ, to chicken Alfredo, to the hawaiian pizza. Their soups, salads, and other sides are really really good suprisingly. I feel it like their food is generally really pricey for some of the cons you get out of them. My last concern is that their staff can be quite rude from time to time by refusing to take a pick up order because it was busy, a little bit of lacking in the social skills.\\n\\n+Unique selections of pizza\\n+Some Pizzas are really really good when are made right\\n+Can eat in, not many places do that.\\n+Really good soups/Salads/Sides\\n\\n-Staff can be rude at times, maybe i'm just unlucky\\n-Some of the pizza seems like they have a lot of grease on them\\n-Lacking consistency? Really acidic sauce sometimes.\\n-Slightly pricy.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1135653</th>\n",
       "      <td>Good spot in Scottsdale. The ambience is great. Menu has a ton of great options for breakfast and lunch. There's also free coffee and other drinks for those waiting for a table and a huge bar area. \\n\\nI ordered the chorizo omelette which came with a side of potatoes, fruit and your choice of toast. The omelette was accompanied with guacamole and a sour cream type of cream. All of the food tasted fresh and of course delicious. Wife ordered strawberry chocolate pancakes and she loved them. I had a bite and they were good considering I don't like tart fruit and chocolate together. \\n\\nService was top notch as the waiter was fast and friendly. We'll definitely come back!</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>359427</th>\n",
       "      <td>For beginners the light-skinned African-American young lady that wore a bun on Saturday, August 7 who work the drive-through has a very bad attitude I repeated myself more than one time and I asked her if I could have supreme fiery shells on my tacos and she kept repeating regular or supreme and I made it very clear that I wanted supreme I get to the window and she still has the same attitude I really hope that her management can speak to her about her customer service skills and that they improve over time so that is why I'm giving two stars for customer service</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1611947</th>\n",
       "      <td>Based on the reviews I saw here, I went with the traditional hot wings and the wedge salad.  The wedge salad was $9, but it was very big.  Apparently it was supposed to come with a warm pretzel, but I got pita bread instead for some reason.  The wings were pretty good and on the larger side.  For $12 your get about 10-12 wings.  Comes with celery and carrots as well.  The meal overall was very filling and pretty good.  The wings weren't award winning in my opinion, but good... especially for a hotel restaurant.  If you are considering eating here, do yourself a favor and go to restaurants.com and print off a coupon.  Also, I have been here twice for lunch now and another nice thing is that it is very quiet - I was the only one here for lunch around 1pm.  Bartender was very nice too and was attentive.  Also have a pretty good selection of draft from Great Lakes Brewery - if you're from out of town, try one.  They are delicious.  Dortmunder Gold is their flagship, but if its the holiday season treat yourself to a Christmas Ale.</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    text  \\\n",
       "1597603                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                Lindo's is a great neighborhood breakfast and lunch spot. Their Special Greek omelet is a wonder to behold. Stuffed with gyro meat, spinach, feta, and tomatoes, it's gigantic but somehow doesn't make me feel like death after eating it. I also love, love, love that you can get grits as your side instead of home fries. Very nice service, and quick on the coffee refills. I'm eager to try their weekend breakfast buffet, as well as their lunch items.   \n",
       "825216   Okay so where do I start, this place is a long time family owned business in Lakewood. It's very well known for their pizza. I've had on numerous occasions and I have mixed feelings about it. Angelo's is definitely an overrated by quite a bit. Some of their pizzas can be quite greasy and their sauce may need some sugar to tone down the acidity of it. However I think they do really well with their different kinds of unique pizzas that you can't find anywhere else, from BBQ, to chicken Alfredo, to the hawaiian pizza. Their soups, salads, and other sides are really really good suprisingly. I feel it like their food is generally really pricey for some of the cons you get out of them. My last concern is that their staff can be quite rude from time to time by refusing to take a pick up order because it was busy, a little bit of lacking in the social skills.\\n\\n+Unique selections of pizza\\n+Some Pizzas are really really good when are made right\\n+Can eat in, not many places do that.\\n+Really good soups/Salads/Sides\\n\\n-Staff can be rude at times, maybe i'm just unlucky\\n-Some of the pizza seems like they have a lot of grease on them\\n-Lacking consistency? Really acidic sauce sometimes.\\n-Slightly pricy.   \n",
       "1135653                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                             Good spot in Scottsdale. The ambience is great. Menu has a ton of great options for breakfast and lunch. There's also free coffee and other drinks for those waiting for a table and a huge bar area. \\n\\nI ordered the chorizo omelette which came with a side of potatoes, fruit and your choice of toast. The omelette was accompanied with guacamole and a sour cream type of cream. All of the food tasted fresh and of course delicious. Wife ordered strawberry chocolate pancakes and she loved them. I had a bite and they were good considering I don't like tart fruit and chocolate together. \\n\\nService was top notch as the waiter was fast and friendly. We'll definitely come back!   \n",
       "359427                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                         For beginners the light-skinned African-American young lady that wore a bun on Saturday, August 7 who work the drive-through has a very bad attitude I repeated myself more than one time and I asked her if I could have supreme fiery shells on my tacos and she kept repeating regular or supreme and I made it very clear that I wanted supreme I get to the window and she still has the same attitude I really hope that her management can speak to her about her customer service skills and that they improve over time so that is why I'm giving two stars for customer service   \n",
       "1611947                                                                                                                                                                                Based on the reviews I saw here, I went with the traditional hot wings and the wedge salad.  The wedge salad was $9, but it was very big.  Apparently it was supposed to come with a warm pretzel, but I got pita bread instead for some reason.  The wings were pretty good and on the larger side.  For $12 your get about 10-12 wings.  Comes with celery and carrots as well.  The meal overall was very filling and pretty good.  The wings weren't award winning in my opinion, but good... especially for a hotel restaurant.  If you are considering eating here, do yourself a favor and go to restaurants.com and print off a coupon.  Also, I have been here twice for lunch now and another nice thing is that it is very quiet - I was the only one here for lunch around 1pm.  Bartender was very nice too and was attentive.  Also have a pretty good selection of draft from Great Lakes Brewery - if you're from out of town, try one.  They are delicious.  Dortmunder Gold is their flagship, but if its the holiday season treat yourself to a Christmas Ale.   \n",
       "\n",
       "         sentiment  \n",
       "1597603          2  \n",
       "825216           1  \n",
       "1135653          2  \n",
       "359427           0  \n",
       "1611947          2  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reviews_dataset.sample(5, random_state=27)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test how individiual words are predictive of the review's sentiment.  \n",
    "Does a neutral share some signals that may create ambiguity both for positive and negative?    \n",
    "If it creates ambiguity for the model, what are ways to prevent the model from making a mistake?  \n",
    "How can we make it easy for the neural network to make this prediction?  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews = reviews_dataset.text.values\n",
    "labels = reviews_dataset.sentiment.values\n",
    "\n",
    "pos_ctr, neu_ctr, neg_ctr, tot_ctr = Counter(), Counter(), Counter(), Counter()\n",
    "\n",
    "for i in range(len(reviews)):\n",
    "    if labels[i]==0:\n",
    "        for word in reviews[i].split():\n",
    "            neg_ctr[word] += 1\n",
    "            tot_ctr[word] += 1\n",
    "    elif labels[i]==1:\n",
    "        for word in reviews[i].split():\n",
    "            neu_ctr[word] += 1\n",
    "            tot_ctr[word] += 1\n",
    "    else:\n",
    "        for word in reviews[i].split():\n",
    "            pos_ctr[word] += 1\n",
    "            tot_ctr[word] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('the', 2177773),\n",
       " ('and', 1903659),\n",
       " ('a', 1314767),\n",
       " ('I', 1165485),\n",
       " ('to', 1051208),\n",
       " ('was', 906061),\n",
       " ('of', 770399),\n",
       " ('is', 755438),\n",
       " ('for', 569964),\n",
       " ('The', 555706)]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pos_ctr.most_common(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('the', 2934770),\n",
       " ('and', 2144415),\n",
       " ('to', 1875007),\n",
       " ('I', 1802984),\n",
       " ('a', 1520209),\n",
       " ('was', 1412821),\n",
       " ('of', 931662),\n",
       " ('for', 801261),\n",
       " ('it', 687814),\n",
       " ('in', 675249)]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "neg_ctr.most_common(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('the', 3100763),\n",
       " ('and', 2122305),\n",
       " ('a', 1830665),\n",
       " ('I', 1731009),\n",
       " ('to', 1541183),\n",
       " ('was', 1520948),\n",
       " ('of', 1058070),\n",
       " ('for', 838079),\n",
       " ('is', 822846),\n",
       " ('The', 759460)]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "neu_ctr.most_common(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_neg_ratios, neu_neg_ratios = Counter(), Counter()\n",
    "threshold = 10000\n",
    "\n",
    "for word, count in tot_ctr.most_common():\n",
    "    \n",
    "    if count > threshold:\n",
    "        pos_neg_ratio = pos_ctr[word] / float(neg_ctr[word]+1)\n",
    "        pos_neg_ratios[word] = pos_neg_ratio\n",
    "        \n",
    "        \n",
    "\n",
    "for word, ratio in pos_neg_ratios.most_common():\n",
    "    \n",
    "    if ratio > 1:\n",
    "        pos_neg_ratios[word] = np.log(ratio)\n",
    "    else:\n",
    "        pos_neg_ratios[word] = -np.log((1/(ratio+0.01)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Excellent', 3.2243248693487416),\n",
       " ('delicious!', 3.1680577995258186),\n",
       " ('amazing!', 2.8654714959461898),\n",
       " ('Love', 2.488407009879809),\n",
       " ('Highly', 2.4656266889924567),\n",
       " ('Great', 2.3480427417997496),\n",
       " ('perfect.', 2.309371596356452),\n",
       " ('Best', 2.3073623958834757),\n",
       " ('die', 2.2553763720977713),\n",
       " (':)', 2.2184379283517845)]"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pos_neg_ratios.most_common(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Worst', -4.190090439741446),\n",
       " ('worst', -3.4128193100101734),\n",
       " ('horrible.', -3.3728462167259146),\n",
       " ('awful.', -3.2597680587154843),\n",
       " ('terrible.', -3.17301575412417),\n",
       " ('rude.', -3.091738272885658),\n",
       " ('rude', -3.0300397820298457),\n",
       " ('horrible', -2.970016599628408),\n",
       " ('terrible', -2.7647884444686297),\n",
       " ('worse', -2.6755962149499495)]"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(reversed(pos_neg_ratios.most_common()))[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Transform dataset into numbers that prove the theory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1611234"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab = tot_ctr.keys()\n",
    "vocab_size = len(vocab)\n",
    "vocab_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "layer_0 = np.zeros((1, vocab_size))\n",
    "\n",
    "word2index = {}\n",
    "for i, word in enumerate(vocab):\n",
    "    word2index[word] = i\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def update_input_layer(review):\n",
    "    global layer_0\n",
    "    layer_0 *= 0\n",
    "    \n",
    "    for word in review.split():\n",
    "        layer_0[0][word2index[word]] += 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1., 1., 1., 1., 3., 2., 2., 2., 1., 1., 1., 3., 1., 1., 1., 1., 2.,\n",
       "       1., 1., 1., 1., 1., 4., 1., 1., 8., 1., 1., 1., 1.])"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "update_input_layer(reviews[0])\n",
    "\n",
    "layer_0[0,:30]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import sys\n",
    "\n",
    "# Encapsulate our neural network in a class\n",
    "class SentimentNetwork:\n",
    "    def __init__(self, reviews, labels, hidden_nodes = 10, learning_rate = 0.1):\n",
    "        np.random.seed(1)\n",
    "\n",
    "        # process the reviews and their associated labels so that everything is ready for training\n",
    "        self.pre_process_data(reviews, labels)\n",
    "        \n",
    "        # Build the network to have the number of hidden nodes and the learning rate that\n",
    "        # were passed into this initializer. Make the same number of input nodes as\n",
    "        # there are vocabulary words and create a single output node.\n",
    "        self.init_network(len(self.review_vocab), hidden_nodes, 1, learning_rate)\n",
    "\n",
    "    def pre_process_data(self, reviews, labels):\n",
    "        \n",
    "        # populate review_vocab with all of the words in the given reviews\n",
    "        review_vocab = set()\n",
    "        for review in reviews:\n",
    "            for word in review.split(\" \"):\n",
    "                review_vocab.add(word)\n",
    "\n",
    "        # Convert the vocabulary set to a list so we can access words via indices\n",
    "        self.review_vocab = list(review_vocab)\n",
    "        \n",
    "        # populate label_vocab with all of the words in the given labels.\n",
    "        label_vocab = set()\n",
    "        for label in labels:\n",
    "            label_vocab.add(label)\n",
    "        \n",
    "        # Convert the label vocabulary set to a list so we can access labels via indices\n",
    "        self.label_vocab = list(label_vocab)\n",
    "        \n",
    "        # Store the sizes of the review and label vocabularies.\n",
    "        self.review_vocab_size = len(self.review_vocab)\n",
    "        self.label_vocab_size = len(self.label_vocab)\n",
    "        \n",
    "        # Create a dictionary of words in the vocabulary mapped to index positions\n",
    "        self.word2index = {}\n",
    "        for i, word in enumerate(self.review_vocab):\n",
    "            self.word2index[word] = i\n",
    "        \n",
    "        # Create a dictionary of labels mapped to index positions\n",
    "        self.label2index = {}\n",
    "        for i, label in enumerate(self.label_vocab):\n",
    "            self.label2index[label] = i\n",
    "            \n",
    "            \n",
    "    def init_network(self, input_nodes, hidden_nodes, output_nodes, learning_rate):\n",
    "        self.input_nodes = input_nodes\n",
    "        self.hidden_nodes = hidden_nodes\n",
    "        self.output_nodes = output_nodes\n",
    "\n",
    "        self.learning_rate = learning_rate\n",
    "\n",
    "        # Initialize weights\n",
    "\n",
    "        # Weights between the input layer and the hidden layer.\n",
    "        self.weights_0_1 = np.zeros((self.input_nodes,self.hidden_nodes))\n",
    "    \n",
    "        # Weights between the hidden layer and the output layer.\n",
    "        self.weights_1_2 = np.random.normal(0.0, self.output_nodes**-0.5, \n",
    "                                                (self.hidden_nodes, self.output_nodes))\n",
    "        \n",
    "        # The input layer, a two-dimensional matrix with shape 1 x input_nodes\n",
    "        self.layer_0 = np.zeros((1,input_nodes))\n",
    "\n",
    "\n",
    "    def update_input_layer(self,review):\n",
    "\n",
    "        # clear out previous state, reset the layer to be all 0s\n",
    "        self.layer_0 *= 0\n",
    "        \n",
    "        for word in review.split(\" \"):\n",
    "            # ensures the word is actually a key in word2index before\n",
    "            # accessing it This allows us to ignore unknown\n",
    "            # words encountered in new reviews.\n",
    "            if(word in self.word2index.keys()):\n",
    "                self.layer_0[0][self.word2index[word]] += 1\n",
    "    \n",
    "    def softmax(self, L):\n",
    "        return np.exp(L)/np.sum(np.exp(L))\n",
    "    \n",
    "    def softmax_output_3_derivative(self,output):\n",
    "        return output * (1 - output)\n",
    "    \n",
    "    def get_target_for_label(self,label):\n",
    "        if(label == 'POSITIVE'):\n",
    "            return 1\n",
    "        else:\n",
    "            return 0\n",
    "        \n",
    "    def sigmoid(self,x):\n",
    "        return 1 / (1 + np.exp(-x))\n",
    "    \n",
    "    def sigmoid_output_2_derivative(self,output):\n",
    "        return output * (1 - output)\n",
    "    \n",
    "    def run(self, review):\n",
    "\n",
    "        # Input Layer\n",
    "        self.update_input_layer(review.lower())\n",
    "\n",
    "        # Hidden layer\n",
    "        layer_1 = self.layer_0.dot(self.weights_0_1)\n",
    "\n",
    "        # Output layer\n",
    "        layer_2 = self.softmax(layer_1.dot(self.weights_1_2))\n",
    "        \n",
    "        # Return POSITIVE for values above greater-than-or-equal-to 0.5 in the output layer;\n",
    "        # return NEGATIVE for other values\n",
    "        #if(layer_2[0] >= 0.5):\n",
    "        #    return \"POSITIVE\"\n",
    "        #else:\n",
    "        #    return \"NEGATIVE\"\n",
    "\n",
    "        print(layer_2)\n",
    "        \n",
    "    def train(self, training_reviews, training_labels):\n",
    "        \n",
    "        # Keep track of correct predictions to display accuracy during training \n",
    "        correct_so_far = 0\n",
    "\n",
    "        start = time.time()\n",
    "        \n",
    "        # loop and run a forward and backward pass updating weights for every item\n",
    "        for i in range(len(training_reviews)):\n",
    "            \n",
    "            # Get the next review and its correct label\n",
    "            review = training_reviews[i]\n",
    "            label = training_labels[i]\n",
    "            \n",
    "            ### Forward pass ###\n",
    "\n",
    "            # Input Layer\n",
    "            self.update_input_layer(review)\n",
    "\n",
    "            # Hidden layer\n",
    "            layer_1 = self.layer_0.dot(self.weights_0_1)\n",
    "\n",
    "            # Output layer\n",
    "            layer_2 = self.softmax(layer_1.dot(self.weights_1_2))\n",
    "            \n",
    "             ### Backward pass ###\n",
    "\n",
    "            # Output error\n",
    "            #layer_2_error = layer_2 - label \n",
    "            #self.get_target_for_label(label) # Output layer error is the difference between desired target and actual output.\n",
    "            #layer_2_delta = layer_2_error * self.softmax_output_3_derivative(layer_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [],
   "source": [
    "sn = SentimentNetwork(reviews[:1000], reviews[:1000], learning_rate=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0.]])"
      ]
     },
     "execution_count": 243,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sn.update_input_layer(reviews[0:1][0])\n",
    "layer_1 = sn.layer_0.dot(sn.weights_0_1)\n",
    "layer_1.dot(sn.weights_1_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.5, 0.5]])"
      ]
     },
     "execution_count": 244,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "layer_2 = 1 / (1 + np.exp(-layer_1.dot(sn.weights_1_2)))\n",
    "layer_2_error = layer_2 -1\n",
    "layer_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.5, -0.5]])"
      ]
     },
     "execution_count": 245,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "layer_2_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.125, -0.125]])"
      ]
     },
     "execution_count": 246,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "layer_2_delta = layer_2_error * (layer_2 * (1 - layer_2))    # error * derivative\n",
    "layer_2_delta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.08950106,  0.14152215,  0.12693725, -0.08693921, -0.0061579 ,\n",
       "         0.05285913,  0.06244385, -0.00299444,  0.0928331 , -0.05524528]])"
      ]
     },
     "execution_count": 247,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "layer_1_error = layer_2_delta.dot(sn.weights_1_2.T)  # errors propagated to the hidden layer\n",
    "layer_1_delta = layer_1_error  # hidden layer gradients - no nonlinearity so it's the same as the error\n",
    "layer_1_delta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Update the weights\n",
    "sn.weights_1_2 -= layer_1.T.dot(layer_2_delta) * sn.learning_rate # update hidden-to-output weights with gradient descent step\n",
    "sn.weights_0_1 -= sn.layer_0.T.dot(layer_1_delta) * sn.learning_rate # update input-to-hidden weights with gradient descent step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.14858562, -0.43257711],\n",
       "       [-0.37347383, -0.75870339],\n",
       "       [ 0.6119356 , -1.62743362],\n",
       "       [ 1.23376823, -0.53825456],\n",
       "       [ 0.22559471, -0.17633148],\n",
       "       [ 1.03386644, -1.45673947],\n",
       "       [-0.22798339, -0.27156744],\n",
       "       [ 0.80169606, -0.77774057],\n",
       "       [-0.12192515, -0.62073964],\n",
       "       [ 0.02984963,  0.41211259]])"
      ]
     },
     "execution_count": 249,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sn.weights_1_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.02685032, -0.04245665, -0.03808118, ...,  0.00089833,\n",
       "        -0.02784993,  0.01657358],\n",
       "       [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
       "         0.        ,  0.        ],\n",
       "       [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
       "         0.        ,  0.        ],\n",
       "       ...,\n",
       "       [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
       "         0.        ,  0.        ],\n",
       "       [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
       "         0.        ,  0.        ],\n",
       "       [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
       "         0.        ,  0.        ]])"
      ]
     },
     "execution_count": 250,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sn.weights_0_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ True,  True]])"
      ]
     },
     "execution_count": 251,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "layer_2 >= 0.5 and "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Backpropagated error\n",
    "layer_1_error = layer_2_delta.dot(self.weights_1_2.T)  # errors propagated to the hidden layer\n",
    "layer_1_delta = layer_1_error  # hidden layer gradients - no nonlinearity so it's the same as the error\n",
    "\n",
    "# Update the weights\n",
    "self.weights_1_2 -= layer_1.T.dot(layer_2_delta) * self.learning_rate # update hidden-to-output weights with gradient descent step\n",
    "self.weights_0_1 -= self.layer_0.T.dot(layer_1_delta) * self.learning_rate # update input-to-hidden weights with gradient descent step\n",
    "\n",
    "# Keep track of correct predictions.\n",
    "if(layer_2 >= 0.5 and label == 'POSITIVE'):\n",
    "    correct_so_far += 1\n",
    "elif(layer_2 < 0.5 and label == 'NEGATIVE'):\n",
    "    correct_so_far += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    \n",
    "    def train(self, training_reviews, training_labels):\n",
    "        \n",
    "        # make sure out we have a matching number of reviews and labels\n",
    "        assert(len(training_reviews) == len(training_labels))\n",
    "        \n",
    "        # Keep track of correct predictions to display accuracy during training \n",
    "        correct_so_far = 0\n",
    "\n",
    "        # Remember when we started for printing time statistics\n",
    "        start = time.time()\n",
    "        \n",
    "        # loop through all the given reviews and run a forward and backward pass,\n",
    "        # updating weights for every item\n",
    "        for i in range(len(training_reviews)):\n",
    "            \n",
    "            # Get the next review and its correct label\n",
    "            review = training_reviews[i]\n",
    "            label = training_labels[i]\n",
    "            \n",
    "            ### Forward pass ###\n",
    "\n",
    "            # Input Layer\n",
    "            self.update_input_layer(review)\n",
    "\n",
    "            # Hidden layer\n",
    "            layer_1 = self.layer_0.dot(self.weights_0_1)\n",
    "\n",
    "            # Output layer\n",
    "            layer_2 = self.softmax(layer_1.dot(self.weights_1_2))\n",
    "            \n",
    "            ### Backward pass ###\n",
    "\n",
    "            # Output error\n",
    "            layer_2_error = layer_2 - label #self.get_target_for_label(label) # Output layer error is the difference between desired target and actual output.\n",
    "            layer_2_delta = layer_2_error * self.softmax_output_3_derivative(layer_2) #self.sigmoid_output_2_derivative(layer_2)\n",
    "\n",
    "            # Backpropagated error\n",
    "            layer_1_error = layer_2_delta.dot(self.weights_1_2.T)  # errors propagated to the hidden layer\n",
    "            layer_1_delta = layer_1_error  # hidden layer gradients - no nonlinearity so it's the same as the error\n",
    "\n",
    "            # Update the weights\n",
    "            self.weights_1_2 -= layer_1.T.dot(layer_2_delta) * self.learning_rate # update hidden-to-output weights with gradient descent step\n",
    "            self.weights_0_1 -= self.layer_0.T.dot(layer_1_delta) * self.learning_rate # update input-to-hidden weights with gradient descent step\n",
    "\n",
    "            # Keep track of correct predictions.\n",
    "            if(layer_2 >= 0.5 and label == 'POSITIVE'):\n",
    "                correct_so_far += 1\n",
    "            elif(layer_2 < 0.5 and label == 'NEGATIVE'):\n",
    "                correct_so_far += 1\n",
    "            \n",
    "            # For debug purposes, print out our prediction accuracy and speed \n",
    "            # throughout the training process. \n",
    "            elapsed_time = float(time.time() - start)\n",
    "            reviews_per_second = i / elapsed_time if elapsed_time > 0 else 0\n",
    "            \n",
    "            sys.stdout.write(\"\\rProgress:\" + str(100 * i/float(len(training_reviews)))[:4] \\\n",
    "                             + \"% Speed(reviews/sec):\" + str(reviews_per_second)[0:5] \\\n",
    "                             + \" #Correct:\" + str(correct_so_far) + \" #Trained:\" + str(i+1) \\\n",
    "                             + \" Training Accuracy:\" + str(correct_so_far * 100 / float(i+1))[:4] + \"%\")\n",
    "            if(i % 2500 == 0):\n",
    "                print(\"\")\n",
    "    \n",
    "    def test(self, testing_reviews, testing_labels):\n",
    "        \"\"\"\n",
    "        Attempts to predict the labels for the given testing_reviews,\n",
    "        and uses the test_labels to calculate the accuracy of those predictions.\n",
    "        \"\"\"\n",
    "        \n",
    "        # keep track of how many correct predictions we make\n",
    "        correct = 0\n",
    "\n",
    "        # we'll time how many predictions per second we make\n",
    "        start = time.time()\n",
    "\n",
    "        # Loop through each of the given reviews and call run to predict\n",
    "        # its label. \n",
    "        for i in range(len(testing_reviews)):\n",
    "            pred = self.run(testing_reviews[i])\n",
    "            if(pred == testing_labels[i]):\n",
    "                correct += 1\n",
    "            \n",
    "            # For debug purposes, print out our prediction accuracy and speed \n",
    "            # throughout the prediction process. \n",
    "\n",
    "            elapsed_time = float(time.time() - start)\n",
    "            reviews_per_second = i / elapsed_time if elapsed_time > 0 else 0\n",
    "            \n",
    "            sys.stdout.write(\"\\rProgress:\" + str(100 * i/float(len(testing_reviews)))[:4] \\\n",
    "                             + \"% Speed(reviews/sec):\" + str(reviews_per_second)[0:5] \\\n",
    "                             + \" #Correct:\" + str(correct) + \" #Tested:\" + str(i+1) \\\n",
    "                             + \" Testing Accuracy:\" + str(correct * 100 / float(i+1))[:4] + \"%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
